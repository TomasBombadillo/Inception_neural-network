{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea4_TLM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/TomasBombadillo/Inception_neural-network/blob/master/Tarea4_TLM.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "nI12EWfT51V8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tbmzYTIH7Q9e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "8902218f-7b02-47af-933c-af2d1f413b27"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets(\"data/\",one_hot=True)\n",
        "X_train = mnist.train.images\n",
        "X_test = mnist.test.images\n",
        "y_train = mnist.train.labels.astype(\"int\")\n",
        "y_test = mnist.test.labels.astype(\"int\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-af9cbe468c3c>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oW88MVCT8aXB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "convos = 64\n",
        "conv_kernel = 3\n",
        "conv_stride = 1\n",
        "inception = [[32],[32,32],[32,48,64]]\n",
        "inc_kernels = [[1],[1,3],[1,3,3]]\n",
        "inc_strides = [[1],[1,1],[1,1,1]]\n",
        "pools = [2,2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n_ghjbOlGdiU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inception_layer(IN,n_convs,kernels,strides):\n",
        "  convo11 = tf.layers.conv2d(IN,\n",
        "                         n_convs[0][0],\n",
        "                         kernel_size=kernels[0][0],\n",
        "                         strides=strides[0][0],\n",
        "                         padding=\"SAME\",\n",
        "                         activation=None)\n",
        "  \n",
        "  convo21 = tf.layers.conv2d(IN,\n",
        "                         n_convs[1][0],\n",
        "                         kernel_size=kernels[1][0],\n",
        "                         strides=strides[1][0],\n",
        "                         padding=\"SAME\",\n",
        "                         activation=None)\n",
        "  convo22 = tf.layers.conv2d(IN,\n",
        "                         n_convs[1][1],\n",
        "                         kernel_size=kernels[1][1],\n",
        "                         strides=strides[1][1],\n",
        "                         padding=\"SAME\",\n",
        "                         activation=None)\n",
        "  \n",
        "  convo31 = tf.layers.conv2d(IN,\n",
        "                         n_convs[2][0],\n",
        "                         kernel_size=kernels[2][0],\n",
        "                         strides=strides[2][0],\n",
        "                         padding=\"SAME\",\n",
        "                         activation=None)\n",
        "  convo32 = tf.layers.conv2d(IN,\n",
        "                         n_convs[2][1],\n",
        "                         kernel_size=kernels[2][1],\n",
        "                         strides=strides[2][1],\n",
        "                         padding=\"SAME\",\n",
        "                         activation=None)\n",
        "  convo33 = tf.layers.conv2d(IN,\n",
        "                         n_convs[2][2],\n",
        "                         kernel_size=kernels[2][2],\n",
        "                         strides=strides[2][2],\n",
        "                         padding=\"SAME\",\n",
        "                         activation=None)\n",
        "  \n",
        "  concat = tf.concat([convo11,convo22,convo33],axis=3)\n",
        "  \n",
        "  convo_end = tf.layers.conv2d(concat,\n",
        "                         n_convs[2][2],\n",
        "                         kernel_size=1,\n",
        "                         strides=1,\n",
        "                         padding=\"SAME\",\n",
        "                         activation=None)\n",
        "  \n",
        "  convo_end = tf.nn.relu(tf.add(convo_end,pool1))\n",
        "  \n",
        "  return convo_end"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Jkj8pQp_7Jq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, 28,28, 1))\n",
        "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
        "\n",
        "convo = tf.layers.conv2d(X,\n",
        "                         convos,\n",
        "                         kernel_size = conv_kernel,\n",
        "                         strides = conv_stride,\n",
        "                         padding = \"SAME\",\n",
        "                         activation = tf.nn.relu)\n",
        "\n",
        "pool1 = tf.layers.max_pooling2d(convo,\n",
        "                                pool_size = pools[0],\n",
        "                                strides = pools[0])\n",
        "\n",
        "incept = inception_layer(pool1,\n",
        "                inception,\n",
        "                inc_kernels,\n",
        "                inc_strides)\n",
        "\n",
        "#skip = tf.nn.relu(tf.add(incept,pool1))\n",
        "\n",
        "\n",
        "\n",
        "pool2 = tf.layers.max_pooling2d(incept,\n",
        "                                pool_size = pools[1], \n",
        "                                strides = pools[1])\n",
        "\n",
        "flat = tf.reshape(pool2, shape=[-1, pool2.shape[1] * pool2.shape[2] * pool2.shape[3]])\n",
        "\n",
        "dense = tf.layers.dense(flat, 64, activation=tf.nn.relu)\n",
        "\n",
        "logits = tf.layers.dense(dense, 10)\n",
        "y_pred=tf.nn.softmax(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vYwsdliDFUu-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=logits)\n",
        "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "training_op = optimizer.minimize(loss)\n",
        "\n",
        "correct = tf.equal(tf.argmax(y,1),tf.argmax(y_pred,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SUVOQ6H_UDh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d61e9f74-9c90-446d-e900-a576ac332f58"
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "batch_size = 50\n",
        "iters=mnist.train.num_examples // batch_size\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        acc_train=0\n",
        "        for iteration in range(iters):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            curr_acc,_=sess.run([accuracy,training_op], feed_dict={X: X_batch.reshape(-1,28,28,1), y: y_batch})\n",
        "            acc_train += curr_acc\n",
        "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images.reshape(-1,28,28,1), y: mnist.test.labels})\n",
        "        print(epoch, \"Train accuracy:\", acc_train/iters, \"Test accuracy:\", acc_test)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 0.940236363072287 Test accuracy: 0.9796\n",
            "1 Train accuracy: 0.9675818181037903 Test accuracy: 0.9757\n",
            "2 Train accuracy: 0.9710545471581545 Test accuracy: 0.9719\n",
            "3 Train accuracy: 0.9732363650473681 Test accuracy: 0.9714\n",
            "4 Train accuracy: 0.9746000018986789 Test accuracy: 0.9708\n",
            "5 Train accuracy: 0.9765818211707202 Test accuracy: 0.9787\n",
            "6 Train accuracy: 0.9770181847160513 Test accuracy: 0.9761\n",
            "7 Train accuracy: 0.9783636393872175 Test accuracy: 0.9764\n",
            "8 Train accuracy: 0.9772727301987735 Test accuracy: 0.9686\n",
            "9 Train accuracy: 0.9784909117221833 Test accuracy: 0.972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OjVR96kMWVhl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}